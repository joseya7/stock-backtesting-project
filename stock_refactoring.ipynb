{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jason/Desktop/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-834e77d1aa0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#KOSPI200 데이터 추출하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkospi_200\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jason/Desktop/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkospi_200_name_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkospi_200\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkospi_200\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkospi_200_name_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkospi_200_name_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jason/Desktop/pair_name_code.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jason/Desktop/data.csv'"
     ]
    }
   ],
   "source": [
    "#KOSPI200 데이터 추출하기\n",
    "kospi_200 = pd.read_csv('/home/jason/Desktop/data.csv')\n",
    "kospi_200_name_code = kospi_200.drop(kospi_200.columns[[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]], axis=1)\n",
    "kospi_200_name_code\n",
    "kospi_200_name_code.to_csv('/home/jason/Desktop/pair_name_code.csv',index=False)\n",
    "myList = [\"027410\",\"282330\",\"138930\",\"001040\",\"079160\",\"000120\",\"097950\",\"005830\",\"000990\",\"007700\",\"114090\",\"078930\",\"006360\",\"007070\",\"012630\",\"294870\",\"011200\",\"001060\",\"105560\",\"002380\",\"016380\",\"030200\",\"033780\",\"093050\",\"003550\",\"034220\",\"001120\",\"051900\",\"032640\",\"011070\",\"066570\",\"108670\",\"051910\",\"079550\",\"006260\",\"010120\",\"035420\",\"005940\",\"010060\",\"005490\",\"064960\",\"010950\",\"034730\",\"011790\",\"001740\",\"006120\",\"096770\",\"285130\",\"017670\",\"000660\",\"005610\",\"035250\",\"010130\",\"002240\",\"011780\",\"073240\",\"000270\",\"024110\",\"025860\",\"002350\",\"251270\",\"006280\",\"005250\",\"004370\",\"019680\",\"000210\",\"001680\",\"047040\",\"042660\",\"069620\",\"006650\",\"003490\",\"192080\",\"001230\",\"026960\",\"000640\",\"170900\",\"049770\",\"014820\",\"000150\",\"241560\",\"042670\",\"034020\",\"115390\",\"032350\",\"023530\",\"004000\",\"004990\",\"005300\",\"011170\",\"002270\",\"071840\",\"204320\",\"008560\",\"006800\",\"003850\",\"003000\",\"005180\",\"006400\",\"028260\",\"207940\",\"032830\",\"018260\",\"028050\",\"009150\",\"005930\",\"010140\",\"016360\",\"029780\",\"000810\",\"145990\",\"000070\",\"004490\",\"001430\",\"068270\",\"004170\",\"031430\",\"055550\",\"003410\",\"002790\",\"090430\",\"020560\",\"010780\",\"018250\",\"012750\",\"036570\",\"111770\",\"003520\",\"000670\",\"007310\",\"271560\",\"001800\",\"316140\",\"014830\",\"000100\",\"214320\",\"139480\",\"007570\",\"020150\",\"030000\",\"185750\",\"035720\",\"192820\",\"120110\",\"021240\",\"192400\",\"284740\",\"003240\",\"009410\",\"028670\",\"047050\",\"003670\",\"103140\",\"086790\",\"000080\",\"036460\",\"071050\",\"015760\",\"009540\",\"161890\",\"161390\",\"000240\",\"047810\",\"060980\",\"008930\",\"128940\",\"009240\",\"020000\",\"105630\",\"014680\",\"018880\",\"009420\",\"006390\",\"051600\",\"052690\",\"180640\",\"000880\",\"088350\",\"009830\",\"012450\",\"000720\",\"005440\",\"086280\",\"064350\",\"012330\",\"010620\",\"069960\",\"017800\",\"011210\",\"004020\",\"267250\",\"005380\",\"001450\",\"057050\",\"008770\",\"241590\",\"004800\",\"093370\",\"081660\",\"069260\"]\n",
    "m = np.asarray(myList)\n",
    "kospi_200_name_code['종목코드'] = myList\n",
    "kospi_200_name_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Market</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "      <th>ListingDate</th>\n",
       "      <th>SettleMonth</th>\n",
       "      <th>Representative</th>\n",
       "      <th>HomePage</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060310</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>3S</td>\n",
       "      <td>특수 목적용 기계 제조업</td>\n",
       "      <td>반도체 웨이퍼 캐리어</td>\n",
       "      <td>2002-04-23</td>\n",
       "      <td>03월</td>\n",
       "      <td>박종익, 김세완 (각자 대표이사)</td>\n",
       "      <td>http://www.3sref.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>095570</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>산업용 기계 및 장비 임대업</td>\n",
       "      <td>렌탈(파렛트, OA장비, 건설장비)</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>12월</td>\n",
       "      <td>이현우</td>\n",
       "      <td>http://www.ajnet.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006840</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>AK홀딩스</td>\n",
       "      <td>기타 금융업</td>\n",
       "      <td>지주사업</td>\n",
       "      <td>1999-08-11</td>\n",
       "      <td>12월</td>\n",
       "      <td>채형석, 이석주(각자 대표이사)</td>\n",
       "      <td>http://www.aekyunggroup.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>054620</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>APS홀딩스</td>\n",
       "      <td>기타 금융업</td>\n",
       "      <td>인터넷 트래픽 솔루션</td>\n",
       "      <td>2001-12-04</td>\n",
       "      <td>12월</td>\n",
       "      <td>정기로</td>\n",
       "      <td>http://www.apsholdings.co.kr</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265520</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>AP시스템</td>\n",
       "      <td>특수 목적용 기계 제조업</td>\n",
       "      <td>디스플레이 제조 장비</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>12월</td>\n",
       "      <td>김영주</td>\n",
       "      <td>http://www.apsystems.co.kr</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>000547</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>흥국화재2우B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>000545</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>흥국화재우</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>003280</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>해상 운송업</td>\n",
       "      <td>외항화물운송업(케미컬탱커)</td>\n",
       "      <td>1976-06-29</td>\n",
       "      <td>12월</td>\n",
       "      <td>이환구</td>\n",
       "      <td>http://www.heung-a.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>037440</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>희림</td>\n",
       "      <td>건축기술, 엔지니어링 및 관련 기술 서비스업</td>\n",
       "      <td>설계 및 감리용역</td>\n",
       "      <td>2000-02-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>정영균, 이목운, 허철호, 염두성 (각자대표)</td>\n",
       "      <td>http://www.heerim.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>238490</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>힘스</td>\n",
       "      <td>특수 목적용 기계 제조업</td>\n",
       "      <td>OLED Mask 인장기, OLED Mask 검사기 등</td>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>12월</td>\n",
       "      <td>김주환</td>\n",
       "      <td>http://www.hims.co.kr</td>\n",
       "      <td>인천광역시</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2585 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol  Market     Name                    Sector  \\\n",
       "0     060310  KOSDAQ       3S             특수 목적용 기계 제조업   \n",
       "1     095570   KOSPI   AJ네트웍스           산업용 기계 및 장비 임대업   \n",
       "2     006840   KOSPI    AK홀딩스                    기타 금융업   \n",
       "3     054620  KOSDAQ   APS홀딩스                    기타 금융업   \n",
       "4     265520  KOSDAQ    AP시스템             특수 목적용 기계 제조업   \n",
       "...      ...     ...      ...                       ...   \n",
       "2580  000547   KOSPI  흥국화재2우B                       NaN   \n",
       "2581  000545   KOSPI    흥국화재우                       NaN   \n",
       "2582  003280   KOSPI     흥아해운                    해상 운송업   \n",
       "2583  037440  KOSDAQ       희림  건축기술, 엔지니어링 및 관련 기술 서비스업   \n",
       "2584  238490  KOSDAQ       힘스             특수 목적용 기계 제조업   \n",
       "\n",
       "                            Industry ListingDate SettleMonth  \\\n",
       "0                        반도체 웨이퍼 캐리어  2002-04-23         03월   \n",
       "1                렌탈(파렛트, OA장비, 건설장비)  2015-08-21         12월   \n",
       "2                               지주사업  1999-08-11         12월   \n",
       "3                        인터넷 트래픽 솔루션  2001-12-04         12월   \n",
       "4                        디스플레이 제조 장비  2017-04-07         12월   \n",
       "...                              ...         ...         ...   \n",
       "2580                             NaN         NaT         NaN   \n",
       "2581                             NaN         NaT         NaN   \n",
       "2582                  외항화물운송업(케미컬탱커)  1976-06-29         12월   \n",
       "2583                       설계 및 감리용역  2000-02-03         12월   \n",
       "2584  OLED Mask 인장기, OLED Mask 검사기 등  2017-07-20         12월   \n",
       "\n",
       "                 Representative                       HomePage Region  \n",
       "0            박종익, 김세완 (각자 대표이사)           http://www.3sref.com  서울특별시  \n",
       "1                           이현우         http://www.ajnet.co.kr  서울특별시  \n",
       "2             채형석, 이석주(각자 대표이사)  http://www.aekyunggroup.co.kr  서울특별시  \n",
       "3                           정기로   http://www.apsholdings.co.kr    경기도  \n",
       "4                           김영주     http://www.apsystems.co.kr    경기도  \n",
       "...                         ...                            ...    ...  \n",
       "2580                        NaN                            NaN    NaN  \n",
       "2581                        NaN                            NaN    NaN  \n",
       "2582                        이환구         http://www.heung-a.com  서울특별시  \n",
       "2583  정영균, 이목운, 허철호, 염두성 (각자대표)          http://www.heerim.com  서울특별시  \n",
       "2584                        김주환          http://www.hims.co.kr  인천광역시  \n",
       "\n",
       "[2585 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krx = fdr.StockListing('KRX')\n",
    "krx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 한국 주식 종목 정보 추출\n",
    "drop_col_list = ['SettleMonth', 'Representative', 'HomePage', 'Region']\n",
    "krx = krx.drop(columns = drop_col_list)\n",
    "krx = krx.dropna()\n",
    "krx.to_csv('/home/jason/Desktop/krxData.csv', index=False)\n",
    "name_list = krx['Name'].tolist()\n",
    "len(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list_aluko = [x for x in name_list if(x!='알루코')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Market</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "      <th>ListingDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>001780</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>알루코</td>\n",
       "      <td>1차 비철금속 제조업</td>\n",
       "      <td>알루미늄제품,샷시 제조</td>\n",
       "      <td>2007-06-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol Market Name       Sector      Industry ListingDate\n",
       "1318  001780  KOSPI  알루코  1차 비철금속 제조업  알루미늄제품,샷시 제조  2007-06-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krx.loc[krx['Symbol']==\"001780\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwlf_path=\"/home/jason/Desktop/lwlf.csv\"\n",
    "csv_path=\"/home/jason/Desktop/temp.csv\"\n",
    "json_path=\"/home/jason/Desktop/stock.json\"\n",
    "dir_path = '/home/jason/Desktop/stockData'\n",
    "\n",
    "lwlf_path_kaggle = '../input/stockdata/lwlf.csv'\n",
    "csv_path_kaggle = '../working/temp.csv'\n",
    "json_path_kaggle = '../working/stock.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1985-01-01'\n",
    "end_date = '2020-07-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#매달 마지막주의 금요일들을 return한다.\n",
    "def get_last_lwlf(path, extract_num='default'):\n",
    "    lwlf_raw_data = pd.read_csv(path)\n",
    "    lwlf = list(lwlf_raw_data['Date'])\n",
    "    if extract_num != 'default':\n",
    "        return lwlf[-extract_num:]\n",
    "    return lwlf\n",
    "\n",
    "lwlf = get_last_lwlf(lwlf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Symbol-Name Dictionary\n",
    "def symbol_name_dictionary():\n",
    "    krx = fdr.StockListing('KRX')\n",
    "    dict_krx = {k: v for k, v in zip(krx.Symbol, krx.Name)}\n",
    "    return dict_krx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Crate Symbo-Name tuple in list\n",
    "def symbol_name_listuple():\n",
    "    krx = fdr.StockListing('KRX')\n",
    "    tuple_list = list(tuple(zip(krx.Symbol, krx.Name)))\n",
    "    return tuple_list\n",
    "\n",
    "krx_tup_list=symbol_name_listuple()\n",
    "krx_tup_list\n",
    "len(krx_tup_list)\n",
    "my_dict = symbol_name_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출할 주식 종목 수: 10\n",
      "전체 한국 주식 종목 수 :  2585\n"
     ]
    }
   ],
   "source": [
    "#Sampling\n",
    "def sampling_stock_by_ticker(ticker, sym_nam_dict):\n",
    "    if isinstance(ticker, list):\n",
    "        return dict((k,v) for k, v in sym_nam_dict.items() if k in ticker)\n",
    "    return dict((k,v) for k, v in sym_nam_dict.items() if k == ticker)\n",
    "\n",
    "def sampling_stock_by_name(name, sym_nam_dict):\n",
    "    if isinstance(name, list):\n",
    "        return dict((k,v) for k, v in sym_nam_dict.items() if v in name)\n",
    "    return dict((k,v) for k, v in sym_nam_dict.items() if v == name)\n",
    "\n",
    "def sampling_stock_by_name_tup(name, sym_nam_tup):\n",
    "    if isinstance(name, list):\n",
    "        return list(tuple((k,v) for k, v in sym_nam_tup if v in name))\n",
    "    return list(tuple((k,v) for k, v in sym_nam_tup if v == name))\n",
    "\n",
    "three_dicts=sampling_stock_by_name(['삼성전자', '카카오', 'NAVER'], my_dict)\n",
    "#name_list : krx전체 주식 목록(이름)\n",
    "#error_test_list : 숫자가 맞지 않는 주식 테스트 목록\n",
    "tup_list = sampling_stock_by_name_tup(['삼성전자', '카카오', 'NAVER', 'LG생활건강', '셀트리온', '아모레퍼시픽', '삼성물산', '씨젠', '현대차', 'POSCO'], krx_tup_list)\n",
    "print('추출할 주식 종목 수:',len(tup_list))\n",
    "print('전체 한국 주식 종목 수 : ', len(krx_tup_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('051900', 'LG생활건강'), ('035420', 'NAVER'), ('005930', '삼성전자'), ('068270', '셀트리온'), ('090430', '아모레퍼시픽'), ('035720', '카카오')]\n"
     ]
    }
   ],
   "source": [
    "print(tup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, path, i):\n",
    "    df.to_csv(path + f'{i}' + '번째.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_manually(df,path,number):\n",
    "    df.to_csv(path + f'{number} + 번째.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(path):\n",
    "    kb = os.path.getsize(path)\n",
    "    test = str(kb)\n",
    "    print(re.sub(r'(?<!^)(?=(\\d{3})+$)', r'.', test), 'MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def csv_converter_json(csv_path, json_path):\n",
    "\n",
    "\n",
    "    entries = []\n",
    "    #the with statement is better since it handles closing your file properly after usage.\n",
    "    with open(csv_path, 'r', encoding='utf8') as csvfile:\n",
    "        #python's standard dict is not guaranteeing any order, \n",
    "        #but if you write into an OrderedDict, order of write operations will be kept in output.\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            entries.append(row)\n",
    "    \n",
    "    output = {\n",
    "        \"stock\": entries\n",
    "    }\n",
    "\n",
    "    with open(json_path, 'w', encoding='UTF-8-sig') as jsonfile:\n",
    "        jsonfile.write(json.dumps(output, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(knicker_tuple,lwlf_list,start_date,end_date):\n",
    "    #Initializing dataframe\n",
    "    init_columns=['Date', 'Knicker', 'Name', 'Price']\n",
    "    result_df = pd.DataFrame(columns=init_columns)\n",
    "\n",
    "    \n",
    "    df = fdr.DataReader(knicker_tuple[0], start_date, end_date)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(['Open', 'High', 'Low', 'Volume', 'Change'], axis=1)\n",
    "    df = df.loc[df['Date'].isin(lwlf_list)]\n",
    "    df = df.rename({'Close':'Price'}, axis=1)\n",
    "    df.insert(1, \"Knicker\", knicker_tuple[0])\n",
    "    df.insert(2, \"Name\", knicker_tuple[1])\n",
    "    result_df = result_df.append(df)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where로 검색하기 위해서 type을 모두 string으로 맞춘다.\n",
    "\n",
    "def skipped_minus(main_df, val_df, sample_lwlf, minus=1):\n",
    "    string_date=[]\n",
    "    \n",
    "    #When DoubleGotcha\n",
    "    if 'DoubleGotcha!' in val_df.values:\n",
    "        dg_skipped_list = []\n",
    "        dg_adjusted_list = []\n",
    "        dg_df = val_df.loc[val_df['Index']==\"DoubleGotcha!\"]\n",
    "        dg_df = dg_df.reset_index()\n",
    "        dg_str = datetime.datetime.strftime(dg_df['Date'][0], \"%m/%d/%Y\")\n",
    "        dg_lwlf=np.asarray(sample_lwlf)\n",
    "        result = np.where(dg_str==dg_lwlf)\n",
    "        prev_1st = result[0][0]-2\n",
    "        dg_skipped_list.append(dg_lwlf[prev_1st])\n",
    "        for i in dg_skipped_list:\n",
    "            date=datetime.datetime.strptime(i, '%m/%d/%Y').date()-datetime.timedelta(1)\n",
    "            dg_adjusted_list.append(date)\n",
    "        bg_data_tuple = tuple(zip(dg_adjusted_list, val_df['Knicker'], val_df['Name']))\n",
    "        \n",
    "        for i, n in enumerate(bg_data_tuple):    \n",
    "            bg_new_df = fdr.DataReader(bg_data_tuple[i][1], bg_data_tuple[i][0], bg_data_tuple[i][0])\n",
    "            bg_new_df = bg_new_df.reset_index()\n",
    "            bg_new_df = bg_new_df.drop(['Open', 'High', 'Low', 'Volume', 'Change'], axis=1)\n",
    "            bg_new_df = bg_new_df.rename({'Close':'Price'}, axis=1)\n",
    "            bg_new_df.insert(1, \"Knicker\", bg_data_tuple[i][1])\n",
    "            bg_new_df.insert(2, \"Name\", bg_data_tuple[i][2])\n",
    "            main_df = main_df.append(bg_new_df, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    #When No DoubleGotcha    \n",
    "    for i in val_df['Date']:\n",
    "        my_str = datetime.datetime.strftime(i, \"%m/%d/%Y\")\n",
    "        string_date.append(my_str)\n",
    "    skipped_list=[]\n",
    "    sample_lwlf=np.asarray(sample_lwlf)\n",
    "    string_date=np.asarray(string_date)\n",
    "    for i in string_date:\n",
    "        result = np.where(i==sample_lwlf)\n",
    "        prev = result[0][0]-1\n",
    "        skipped_list.append(sample_lwlf[prev])\n",
    "    adjusted_list=[]\n",
    "    for i in skipped_list:\n",
    "        date=datetime.datetime.strptime(i, '%m/%d/%Y').date()-datetime.timedelta(minus)\n",
    "        adjusted_list.append(date)\n",
    "    data_tuple = tuple(zip(adjusted_list, val_df['Knicker'], val_df['Name']))\n",
    "    for i, n in enumerate(data_tuple):    \n",
    "        new_df = fdr.DataReader(data_tuple[i][1], data_tuple[i][0], data_tuple[i][0])\n",
    "        new_df = new_df.reset_index()\n",
    "        new_df = new_df.drop(['Open', 'High', 'Low', 'Volume', 'Change'], axis=1)\n",
    "        new_df = new_df.rename({'Close':'Price'}, axis=1)\n",
    "        new_df.insert(1, \"Knicker\", data_tuple[i][1])\n",
    "        new_df.insert(2, \"Name\", data_tuple[i][2])\n",
    "        main_df = main_df.append(new_df, ignore_index=True)\n",
    "        \n",
    "    main_df.reset_index()\n",
    "    main_df = main_df.drop(['Index', 'Month'], axis=1)\n",
    "    main_df['Date'] =pd.to_datetime(main_df.Date) \n",
    "    main_df.sort_values(by='Date', inplace=True)\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(sam_tup, lwlf, start_date, end_date):\n",
    "    df = get_data(sam_tup, lwlf, start_date, end_date)\n",
    "    val_df = skip_validation(df)\n",
    "    res_df = skipped_minus(df, val_df, lwlf, minus=1)\n",
    "    minus_arg = 1\n",
    "    while(len(val_df)>=1):\n",
    "        minus_arg+=1;\n",
    "        print('Name :', res_df['Name'][0])\n",
    "        val_df = skip_validation(res_df)\n",
    "        res_df = skipped_minus(res_df, val_df, lwlf, minus_arg)\n",
    "    res_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_validation(df):\n",
    "    df['Month']=pd.DatetimeIndex(df['Date']).month\n",
    "    inc = [0]\n",
    "    for i, n in enumerate(zip(df['Month'][1:], df['Month'][:-1]), 0):\n",
    "        if (n[0] - n[1]) == 1 :\n",
    "            inc.append('+1')\n",
    "        elif (n[0] - n[1]) == -11:\n",
    "            inc.append('Next Year')\n",
    "        elif (n[0] - n[1]) == -9:\n",
    "            inc.append('DoubleGotcha!')\n",
    "        else:\n",
    "            inc.append('Gotcha!')\n",
    "            \n",
    "    df['Index'] = inc\n",
    "    \n",
    "    if(len(df.loc[df['Index']=='DoubleGotcha!'])>=1):\n",
    "        print('Total of Gotcha : ',len(df.loc[df['Index']=='Gotcha!'].append(df.loc[df['Index']=='DoubleGotcha!'])))\n",
    "        print('Number of DoubleGotcha : ',len(df.loc[df['Index']=='DoubleGotcha!']))\n",
    "        return df.loc[df['Index']=='Gotcha!'].append(df.loc[df['Index']=='DoubleGotcha!'])\n",
    "    \n",
    "    \n",
    "    print('Number of Gotcha : ',len(df.loc[df['Index']=='Gotcha!']))\n",
    "    return df.loc[df['Index']=='Gotcha!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sam_df = execute(nav_tup, lwlf, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_months(df):\n",
    "    end_date_year=df['Date'].iloc[-1].year\n",
    "    end_date_month=df['Date'].iloc[-1].month\n",
    "    start_date_year=df['Date'].iloc[0].year\n",
    "    start_date_month=df['Date'].iloc[0].month\n",
    "    num_months=(end_date_year - start_date_year) * 12 + (end_date_month - start_date_month)+1\n",
    "    return num_months == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data(tup_list, lwlf, start_date, end_date):\n",
    "    init_columns=['Date', 'Knicker', 'Name', 'Price']\n",
    "    result_df = pd.DataFrame(columns=init_columns)\n",
    "    error_stock_list = []\n",
    "    for index, tuple_data in enumerate(tup_list):\n",
    "        if(index % 550==0):\n",
    "            print('★★★저장되었습니다★★★')\n",
    "            save_data(result_df, dir_path, index)\n",
    "            \n",
    "        df = execute(tuple_data, lwlf, start_date, end_date)\n",
    "        print(index, '번째입니다')\n",
    "        if check_number_months(df)==False:\n",
    "            print(\"Numbers doesn't match: \", tuple_data)\n",
    "            error_stock_list.append(tuple_data[1])\n",
    "            continue\n",
    "        else:\n",
    "            print('Number match!')\n",
    "            print(datetime.datetime.now().time())\n",
    "        result_df = result_df.append(df)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    result_df['Date']=result_df['Date'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "    return result_df, error_stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★저장되었습니다★★★\n",
      "Total of Gotcha :  11\n",
      "Number of DoubleGotcha :  1\n",
      "Name : LG생활건강\n",
      "Number of Gotcha :  1\n",
      "Name : LG생활건강\n",
      "Number of Gotcha :  0\n",
      "0 번째입니다\n",
      "Number match!\n",
      "16:29:04.375618\n",
      "Total of Gotcha :  11\n",
      "Number of DoubleGotcha :  1\n",
      "Name : NAVER\n",
      "Number of Gotcha :  1\n",
      "Name : NAVER\n",
      "Number of Gotcha :  0\n",
      "1 번째입니다\n",
      "Number match!\n",
      "16:29:08.294851\n",
      "Total of Gotcha :  15\n",
      "Number of DoubleGotcha :  1\n",
      "Name : POSCO\n",
      "Number of Gotcha :  4\n",
      "Name : POSCO\n",
      "Number of Gotcha :  2\n",
      "Name : POSCO\n",
      "Number of Gotcha :  0\n",
      "2 번째입니다\n",
      "Number match!\n",
      "16:29:14.764953\n",
      "Total of Gotcha :  3\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 삼성물산\n",
      "Number of Gotcha :  0\n",
      "3 번째입니다\n",
      "Number match!\n",
      "16:29:15.473110\n",
      "Total of Gotcha :  15\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 삼성전자\n",
      "Number of Gotcha :  4\n",
      "Name : 삼성전자\n",
      "Number of Gotcha :  2\n",
      "Name : 삼성전자\n",
      "Number of Gotcha :  0\n",
      "4 번째입니다\n",
      "Number match!\n",
      "16:29:22.540448\n",
      "Total of Gotcha :  9\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 셀트리온\n",
      "Number of Gotcha :  1\n",
      "Name : 셀트리온\n",
      "Number of Gotcha :  0\n",
      "5 번째입니다\n",
      "Number match!\n",
      "16:29:26.344307\n",
      "Total of Gotcha :  6\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 씨젠\n",
      "Number of Gotcha :  1\n",
      "Name : 씨젠\n",
      "Number of Gotcha :  0\n",
      "6 번째입니다\n",
      "Number match!\n",
      "16:29:28.265285\n",
      "Total of Gotcha :  8\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 아모레퍼시픽\n",
      "Number of Gotcha :  1\n",
      "Name : 아모레퍼시픽\n",
      "Number of Gotcha :  0\n",
      "7 번째입니다\n",
      "Number match!\n",
      "16:29:30.628792\n",
      "Total of Gotcha :  13\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 카카오\n",
      "Number of Gotcha :  3\n",
      "Name : 카카오\n",
      "Number of Gotcha :  2\n",
      "Name : 카카오\n",
      "Number of Gotcha :  0\n",
      "8 번째입니다\n",
      "Number match!\n",
      "16:29:35.342651\n",
      "Total of Gotcha :  15\n",
      "Number of DoubleGotcha :  1\n",
      "Name : 현대차\n",
      "Number of Gotcha :  4\n",
      "Name : 현대차\n",
      "Number of Gotcha :  2\n",
      "Name : 현대차\n",
      "Number of Gotcha :  0\n",
      "9 번째입니다\n",
      "Number match!\n",
      "16:29:40.089590\n"
     ]
    }
   ],
   "source": [
    "final = append_data(tup_list, lwlf, start_date, end_date)\n",
    "final_df = final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Knicker</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Knicker, Name, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_manually(final_df, csv_path, f'{1100+447}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2097+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.597.801 MB\n"
     ]
    }
   ],
   "source": [
    "save_data_manually(final_df, csv_path, f'{1100+447}')\n",
    "csv_converter_json(csv_path, json_path)\n",
    "get_file_size(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=fdr.DataReader('005930', '2014-01-30','2014-01-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 4000\n",
    "# sam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path=\"/home/jason/Desktop/stock_2097-2353.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_converter_json('/home/jason/Desktop/stockData(2097-2353).csv', json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stock",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
